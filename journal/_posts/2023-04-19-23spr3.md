---
layout: post
title: Scaling GP Regression up
use_math: true
category: journal
---


# OSC GPUS

[OSC's Website](https://www.osc.edu/resources/technical_support/supercomputers/gpu_computing) lists the all the available GPUs. The default node is an Owens P100 which has 1 GPU per node and 16GB of memory per GPU. One way I can improve my results is by using better GPUs. The Pitzer Quad V100 has 4 GPUs per GPU node of each 32 GB memory and the newest Ascend A100 nodes have 4 GPUs per node with 300GB GPU memory per node. 

# Finding Theoretical MSE and MAPE

I modified the Fuchs data generation code to include columns for the noiseless max/total/avg energy. This way, I can compute a reference value for the MSE and Percent Error which would be exactly what the testing error should converge to. 

![image](https://user-images.githubusercontent.com/98538788/233175949-93664ca8-a55b-495a-9950-f402780966f6.png)

Above is an example with using GP on 1,000 data points where I have both the estimate in green (which is what I computed in last week's post for the 20,000 point dataset) and the "Ideal" value in blue which is just the error between the noiseless and the noisy energies. We see that these are very close, but I think it might be more sensible to use the "Ideal" value. 

# Trying to run 100000 data points in under 100 seconds

On my CPU, I can run 8000 data points in under 100 seconds using the settings I have been using with good accuracy

![image](https://user-images.githubusercontent.com/98538788/233184121-9cf7249b-cbda-4f87-b429-ff086579d345.png)

![image](https://user-images.githubusercontent.com/98538788/233184145-bddf3903-c91d-4e0c-bbf5-07dd8f4d4334.png)

Running this same code on 1 GPU, I can run a maximum of ... data points

> Coding Block

*Italics Text* 

**Bold Text**

# Things to Do
- Item 1
- Item 2
