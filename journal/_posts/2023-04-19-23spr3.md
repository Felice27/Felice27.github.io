---
layout: post
title: Scaling GP Regression up
use_math: true
category: journal
---


# OSC GPUS

[OSC's Website](https://www.osc.edu/resources/technical_support/supercomputers/gpu_computing) lists the all the available GPUs. The default node is an Owens P100 which has 1 GPU per node and 16GB of memory per GPU. One way I can improve my results is by using better GPUs. The Pitzer Quad V100 has 4 GPUs per GPU node of each 32 GB memory and the newest Ascend A100 nodes have 4 GPUs per node with 300GB GPU memory per node. 

# Finding Theoretical MSE and MAPE

I modified the Fuchs data generation code to include columns for the noiseless max/total/avg energy. This way, I can compute a reference value for the MSE and Percent Error which would be exactly what the testing error should converge to. 

![image](https://user-images.githubusercontent.com/98538788/233175949-93664ca8-a55b-495a-9950-f402780966f6.png)

Above is an example with using GP on 1,000 data points where I have both the estimate in green (which is what I computed in last week's post for the 20,000 point dataset) and the "Ideal" value in blue which is just the error between the noiseless and the noisy energies. We see that these are very close, and I've even re-run this for a 10,000 point dataset and 

> Coding Block

*Italics Text* 

**Bold Text**

# Things to Do
- Item 1
- Item 2
