---
layout: post
title: Fuchs ML Comparison Continued
use_math: true
category: journal
---

# Number of Points to Train
Before candidacy, I was working on exploring different Machine Learning Models with the Fuchs Model. I found that we only needed a really small amount of points to train the model. This was in part due to an error on my part. I wasn't resetting the pytorch model parameters of the neural network in between each training split. To fix this, I just called

> torch.save(model.state_dict(), 'temp.pt')

to save the initial untrained model state and then at the beginning of each training iteration, I called

> model.load_state_dict(torch.load('temp.pt'))

to load this untrained model state. After doing this, I found that the neural network converged to a steady percentage error after around a few thousand data points of training

![image](https://user-images.githubusercontent.com/98538788/231851369-7f811a69-1022-44cf-a26c-af0b81942d5f.png)


# Where MSE and MAPE converges

In the process of creating these noisy datasets, we take the exact Fuchs model prediction for the max/total/average proton energies and add gaussian noise of a certain percentage. For example, 10% noise on some value $x$ would add some error value that is sampled from a normal distribution with mean $\mu = 0$ and standard deviation $\sigma = 0.10 x$. Since this noise is random, it cannot be predicted and it will place a lower bound on the mean squared error (MSE) and mean absolute percentage error (MAPE) we can obtain on noisy data. 

##  MAPE
The gaussian noise we placed on the data was based off of a percentage. If we were using a root mean squared percentage error metric, we would simply find an optimal model has a percentage error equal to the amount of noise we used. However, the mean absolute percentage error will have a numerical factor of $\sqrt{2/\pi}$ difference which can be seen from taking the expectation value 

![image](https://user-images.githubusercontent.com/98538788/231863807-ecadae7d-aeef-4f89-ae1c-a4abf56a3184.png)

For example, if we used 10% gaussian noise ($\epsilon = 0.10$), then we would predict a MAPE of 7.979%.

\begin{equation}
    MAPE = 100 \epsilon \sqrt{\frac{2}{\pi}}
\end{equation}

![image](https://user-images.githubusercontent.com/98538788/231864279-059541af-4958-42a7-8527-188d020ed408.png)


## MSE
MSE is not based on a percentage, unlike our noise, so we need to factor in some sense of scale for a MSE estimate. If we take a noiseless dataset, we can compute the square root of the mean squared max/total/average energies which will be our scale factor. This is $E_\text{scale} = {2.494315e-3, 7.925738e-4, 4.492056e4}$ for max, average, total energy respectively (using a dataset of 20,000 points generated from the Fuchs model and this would change if I changed the range of the inputs that we are scanning over). We multiply this number by the noise level (10% noise would be $\epsilon = 0.10$). Then we square this to get the MSE estimate. 

\begin{equation}
  MSE = (E_\text{scale} \epsilon)^2
\end{equation}

![image](https://user-images.githubusercontent.com/98538788/231866684-10d0ccfb-18fa-4a5c-b06a-3a172ac33932.png)
 
# Things to Do
- Item 1
- Item 2
