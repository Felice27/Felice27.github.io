---
layout: post
title: Fuchs ML Comparison Continued
use_math: true
category: journal
---

# Number of Points to Train
Before candidacy, I was working on exploring different Machine Learning Models with the Fuchs Model. I found that we only needed a really small amount of points to train the model. This was in part due to an error on my part. I wasn't resetting the pytorch model parameters of the neural network in between each training split. To fix this, I just called

> torch.save(model.state_dict(), 'temp.pt')

to save the initial untrained model state and then at the beginning of each training iteration, I called

> model.load_state_dict(torch.load('temp.pt'))

to load this untrained model state. After doing this, I found that the neural network converged to a steady percentage error after around a few thousand data points of training

![image](https://user-images.githubusercontent.com/98538788/231851369-7f811a69-1022-44cf-a26c-af0b81942d5f.png)


# Where MSE and MAPE converges

In the process of creating these noisy datasets, we take the exact Fuchs model prediction for the max/total/average proton energies and add gaussian noise of a certain percentage. For example, 10% noise on some value $x$ would add some error value that is sampled from a normal distribution with mean $\mu = 0$ and standard deviation $\sigma = 0.10 (x)$. Since this noise is random, it cannot be predicted and it will place a lower bound on the mean squared error (MSE) and mean absolute percentage error (MAPE) we can obtain on noisy data. 

##  MAPE
With 10%

# Things to Do
- Item 1
- Item 2
